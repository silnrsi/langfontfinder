#!/bin/env python3

import argparse, os, json, sys, csv, re
from langtag import lookup, langtag
from multiprocessing.pool import Pool
import xml.etree.ElementTree as et


silns = "{urn://www.sil.org/ldml/0.1}"

def procdir(j):
    """Read an LDML file and parse out langtag and font information"""
    l = et.parse(j)
    langn = l.find("identity/language")
    if langn is None:
        return (None, None)
    lang = langn.get("type", None)
    inf = l.find(f"identity/special/{silns}identity")
    if inf is None:
        return (None, None)
    scriptn = l.find("identity/script")
    if scriptn is not None:
        script = scriptn.get("type", None)
    else:
        script = inf.get("script")
    regionn = l.find("identity/territory")
    if regionn is not None:
        region = regionn.get("type", None)
    else:
        region = inf.get("defaultRegion")
    var = l.find("identity/variant")
    if var is not None:
        var = var.get("type", None)
    ltag = "{}-{}-{}".format(lang, script, region).lower().replace("-none", "")
    if var is not None:
        ltag += "-" + var
    try:
        ltagset = lookup(ltag)
        ltag = str(ltagset.tag if args.min else ltagset.full).lower()
    except KeyError:
        pass
    except SyntaxError:
        return (None, None)

    res = {}
    fallback = None
    for f in l.findall(f"special/{silns}external-resources/{silns}font"):
        t = f.get("types", "default")
        for a in t.split(" "):
            fid = f.get("name").replace(" ", "").lower()
            res.setdefault('roles', {}).setdefault(a, []).append(fid)
            feat = f.get('features', '')
            if feat:
                res.setdefault('features', {})[fid] = feat
    return (ltag if len(res) else None, res)


class Classifier:
    """Convert a list of langtags and fonts with features into hierarchical lookup rules."""

    def __init__(self, mapdata):
        self.scripts = [[None, {}]]
        self.regions = []
        self.langs = []
        self.variants = []

    def create_matches(self, mapdata):
        """Convert the langtags + fonts into rules"""
        fields = ("script", "region", "lang", "variant")
        for k, v in mapdata.items():
            key = self._splitkey(k)
            current = 0
            for i, a in enumerate(fields):
                rules = getattr(self, a + "s")[current]
                nrules = getattr(self, fields[i + 1] + "s") if i + 1 < len(fields) else None
                if a in key:
                    val = key[a]
                    if val not in rules[1]:
                        rules[1][val] = len(nrules) if nrules is not None else v
                        if nrules is not None:
                            nrules.append([None, {}])
                    current = rules[1][val]
                else:
                    if rules[0] is None:
                        rules[0] = len(nrules) if nrules is not None else v
                        if nrules is not None:
                            nrules.append([None, {}])
                    current = rules[0]
        def stringifyvar(m):
            return (self._stringify(m[0]), self._stringify(m[1]))
        def stringifyrule(m):
            return (m[0], " ".join(sorted(("{}={}".format(k, v) for k, v in m[1].items()))))
        lastmap = None
        stringifies = [stringifyrule] * (len(fields)-1) + [stringifyvar]
        for i, a in enumerate(reversed(fields)):
            rules = getattr(self, a+"s")
            if lastmap is not None:
                self._apply_map(rules, lastmap)
            r, m = self._simplify_matches(rules, stringifies[-i-1])
            setattr(self, a + "s", r)
            lastmap = m
        for vm in self.variants:
            vm[0] = self._makeres(vm[0])
            vm[1] = {k: self._makeres(v) for k, v in vm[1].items()}

    def _splitkey(self, x):
        """Splits according to a language tag. Subclass and override
        appropriately"""
        l = langtag(x)
        key = {
            k: getattr(l, k)
            for k in ("lang", "script", "region")
            if getattr(l, k, None) is not None
        }
        if key.get("lang", "") == "und":
            del key["lang"]
        var = []
        if l.vars is not None and len(l.vars):
            var.extend(l.vars)
        if l.ns is not None:
            for k in sorted(l.ns.keys()):
                var.extend([k.lower()] + l.ns[k])
        if len(var):
            key["variant"] = "-".join(var)
        return key

    def _simplify_matches(self, matchrules, stringify):
        cache = {}
        outmap = {}
        res = []
        for i, m in enumerate(matchrules):
            key = stringify(m)
            curri = len(res)
            if key not in cache:
                cache[key] = curri
                res.append(m)
            outmap[i] = cache[key]
        return (res, outmap)

    def _apply_map(self, matchrules, rulemap):
        for i, m in enumerate(matchrules):
            if m[0] is None:
                scores = {}
                for k, v in m[1].items():
                    a = rulemap[v]
                    scores[a] = scores.setdefault(a, 0) + 1
                m[0] = max(scores.items(), key=lambda x:x[1])[0]
            else:
                m[0] = rulemap.get(m[0])
            t = {}
            for k, v in m[1].items():
                s = rulemap.get(v)
                if s != m[0]:
                    t[k] = s
            m[1] = t

    def _stringify(self, entry):
        return json.dumps(entry, sort_keys=True)

    def _makeres(self, reskey):
        return reskey
        if reskey is None:
            return None
        family, feats = reskey.split("|")
        res = {"family": family.strip(), "familyid": family.replace(" ", "").lower()}
        if feats is not None and len(feats.strip()):
            res["features"] = feats.strip()
        return res

    def out_matches(self, fname):
        """spit everything out as json"""
        with open(fname, "w") as outf:
            json.dump(
                {
                    "scripts": self.scripts,
                    "regions": self.regions,
                    "langs": self.langs,
                    "variants": self.variants,
                },
                outf,
                indent=2,
            )


parser = argparse.ArgumentParser()
parser.add_argument("indir", help="Directory of files to process")
parser.add_argument("-f", "--fallbacks", help="fallbacks csv")
parser.add_argument("-o", "--outfile", default="fontrules.json", help="Output fontrules.json")
parser.add_argument("--intermediate", help="Output interim results")
parser.add_argument("--min", action="store_true", help="Use a minimal tag rather than maximal")
parser.add_argument("-R", "--resultsort", action="store_true",
                    help="Sort by results, which is inaccurate but helpful for review")
parser.add_argument("-q", "--quiet", action="store_true", help="Minimise output")
parser.add_argument("-j", "--processes", action="store_true", help="Single processor")
parser.add_argument("-l", "--lang", help="Single language to process")
args = parser.parse_args()

jobs = []
if os.path.isdir(args.indir):
    for dp, dn, fn in os.walk(args.indir):
        for f in fn:
            if f.endswith(".xml") and (args.lang is None or args.lang == f[:-4]):
                jobs.append(os.path.join(dp, f))
    ltagmap = {}
else:
    with open(args.indir) as inf:
        ltagmap = json.load(inf)

if not args.quiet:
    print(f"{len(jobs)} files to test")

if not args.processes or len(jobs) == 1:
    ltagmap = dict(procdir(j) for j in jobs)
else:
    p = Pool()
    ltagmap = dict(p.map_async(procdir, jobs).get())
ltagmap = {k: v for k, v in ltagmap.items() if v is not None}

if args.fallbacks:
    with open(args.fallbacks, encoding="utf-8") as inf:
        fb = json.load(inf)
    for s, v in fb.items():
        for r in v:
            d = {a: b for a, b in r.items() if a in ('roles', 'features')}
            # No need for variants, this is script fallback
            if 'regions' in r:
                for k in r['regions']:
                    lt = f"und-{s}-{k}"
                    ltagmap[lt] = d
            else:
                ltagmap[f"und-{s}"] = d

if not args.quiet:
    print(f"Found {len(ltagmap)} entries")
if args.intermediate:
    with open(args.intermediate, "w") as outf:
        json.dump(ltagmap, outf)

c = Classifier(ltagmap)
c.create_matches(ltagmap)
c.out_matches(args.outfile)
